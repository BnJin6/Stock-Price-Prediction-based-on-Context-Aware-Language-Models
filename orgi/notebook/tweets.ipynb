{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "15a4e362-40c6-4775-8b1a-9af1a5fb337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import partial\n",
    "from typing import List, Callable\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "94e3dfb1-514d-498f-a603-66b9d757ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_data_loader(addr: str, columns: List[str], *transforms: Callable[[pd.DataFrame], pd.DataFrame]) -> pd.DataFrame:\n",
    "    # Load the data from the CSV file\n",
    "    df = pd.read_csv(addr, usecols=columns)\n",
    "\n",
    "    # Apply each transform to the DataFrame\n",
    "    for transform in transforms:\n",
    "        df = transform(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Transform index to datetime\n",
    "def index_to_datetime(df, unit=\"s\"):\n",
    "    df.index = pd.to_datetime(df.index, unit=unit)\n",
    "    return df\n",
    "# Transform col to index\n",
    "to_index = lambda col, df: df.set_index(col)\n",
    "# Rename text_plit to text\n",
    "rename = lambda original, new, df: df.rename(columns={original: new})\n",
    "\n",
    "def compute_metrics_classification(labels, preds, probs, metrics_to_return=None):\n",
    "        \"\"\"\n",
    "        Compute classification metrics based on the model's predictions and the true labels.\n",
    "\n",
    "        Args:\n",
    "        labels (any): The true labels.\n",
    "        preds (any): The model's predictions.\n",
    "        probs (any): The model's probabilities\n",
    "        metrics_to_return (list): List of metric names to compute and return.\n",
    "\n",
    "        Returns:\n",
    "        dict: The computed classification metrics.\n",
    "        \"\"\"\n",
    "        if metrics_to_return is None:\n",
    "            metrics_to_return = [\"accuracy\", \"f1\", \"precision\", \"recall\", \"roc_score\", \"confusion_matrix\"]\n",
    "\n",
    "        metrics = {}\n",
    "\n",
    "        if \"precision\" in metrics_to_return or \"recall\" in metrics_to_return or \"f1\" in metrics_to_return:\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "            if \"precision\" in metrics_to_return:\n",
    "                metrics[\"precision\"] = precision\n",
    "            if \"recall\" in metrics_to_return:\n",
    "                metrics[\"recall\"] = recall\n",
    "            if \"f1\" in metrics_to_return:\n",
    "                metrics[\"f1\"] = f1\n",
    "\n",
    "        if \"accuracy\" in metrics_to_return:\n",
    "            metrics[\"accuracy\"] = accuracy_score(labels, preds)\n",
    "\n",
    "        if \"roc_score\" in metrics_to_return:\n",
    "            metrics[\"roc_score\"] = roc_auc_score(labels, probs, multi_class='ovr')\n",
    "\n",
    "        if \"confusion_matrix\" in metrics_to_return:\n",
    "            metrics[\"confusion_matrix\"] = confusion_matrix(labels, preds)\n",
    "\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7296b3-a58e-4b35-a822-75493f9c12c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store the sampled data\n",
    "sampled_tweets = pd.DataFrame()\n",
    "\n",
    "# Process the data in chunks with error handling\n",
    "for i, chunk in enumerate(pd.read_csv('../raw/Bitcoin_tweets.csv', usecols=['text', 'date'], chunksize=500000, on_bad_lines='error', encoding='utf-8', low_memory=True)):\n",
    "    # Convert 'date' column to datetime, coercing errors\n",
    "    chunk['date'] = pd.to_datetime(chunk['date'], errors='coerce')\n",
    "    \n",
    "    # Drop rows with invalid dates\n",
    "    chunk = chunk.dropna(subset=['date'])\n",
    "    \n",
    "    # Convert 'text' column to string and filter out tweets with fewer than 5 words\n",
    "    chunk['text'] = chunk['text'].astype(str)\n",
    "    chunk = chunk[chunk['text'].str.split().str.len() > 4]\n",
    "    \n",
    "    # Sample 5000 tweets per day from this chunk\n",
    "    sampled_chunk = chunk.groupby(chunk['date'].dt.date).apply(\n",
    "        lambda x: x.sample(n=min(5000, len(x)), random_state=1)\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    # Append the sampled data to the main DataFrame\n",
    "    sampled_tweets = pd.concat([sampled_tweets, sampled_chunk], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa25514b-d3ac-43e9-bae5-bde75817c37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-05 16:35:13</td>\n",
       "      <td>In case you want to seel your btc please DM as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-05 17:12:24</td>\n",
       "      <td>ðŸ”„ Prices update in $USD (1 hour):\\n\\n$BTC - 37...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-05 17:30:00</td>\n",
       "      <td>Bitcoin fiat price in last day https://t.co/Bf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-05 17:48:34</td>\n",
       "      <td>SIGN UP FOR #COINTIPLY !!\\n\\n- Claim hourly #b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-05 21:49:40</td>\n",
       "      <td>#blockchain Innovation Done the Polkadot Way A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083222</th>\n",
       "      <td>2022-12-27 23:42:49</td>\n",
       "      <td>Binance is crappy\\n\\nðŸ˜¤ðŸ˜¾ðŸ˜¾ðŸ˜¤ðŸ˜ \\n$BUSD #Bitcoin #BT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083223</th>\n",
       "      <td>2022-12-27 23:47:03</td>\n",
       "      <td>What is Currency? Exchange Rates | Money Instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083224</th>\n",
       "      <td>2022-12-27 23:53:14</td>\n",
       "      <td>I'm playing #lnbingo! This card is for draw 76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083225</th>\n",
       "      <td>2022-12-27 23:46:45</td>\n",
       "      <td>Took a while but still less work than opening ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083226</th>\n",
       "      <td>2022-12-27 23:56:10</td>\n",
       "      <td>I'm playing #lnbingo! This card is for draw 76...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1083227 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date                                               text\n",
       "0       2021-02-05 16:35:13  In case you want to seel your btc please DM as...\n",
       "1       2021-02-05 17:12:24  ðŸ”„ Prices update in $USD (1 hour):\\n\\n$BTC - 37...\n",
       "2       2021-02-05 17:30:00  Bitcoin fiat price in last day https://t.co/Bf...\n",
       "3       2021-02-05 17:48:34  SIGN UP FOR #COINTIPLY !!\\n\\n- Claim hourly #b...\n",
       "4       2021-02-05 21:49:40  #blockchain Innovation Done the Polkadot Way A...\n",
       "...                     ...                                                ...\n",
       "1083222 2022-12-27 23:42:49  Binance is crappy\\n\\nðŸ˜¤ðŸ˜¾ðŸ˜¾ðŸ˜¤ðŸ˜ \\n$BUSD #Bitcoin #BT...\n",
       "1083223 2022-12-27 23:47:03  What is Currency? Exchange Rates | Money Instr...\n",
       "1083224 2022-12-27 23:53:14  I'm playing #lnbingo! This card is for draw 76...\n",
       "1083225 2022-12-27 23:46:45  Took a while but still less work than opening ...\n",
       "1083226 2022-12-27 23:56:10  I'm playing #lnbingo! This card is for draw 76...\n",
       "\n",
       "[1083227 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26889a7f-ee29-4f6e-bdac-a5819f744287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data in chunks with error handling\n",
    "for i, chunk in enumerate(pd.read_csv('../raw/Bitcoin_tweets_dataset_2.csv', usecols=['text', 'date'], chunksize=1000, on_bad_lines='error', encoding='utf-8', low_memory=True)):\n",
    "    # Convert 'date' column to datetime, coercing errors\n",
    "    chunk['date'] = pd.to_datetime(chunk['date'], errors='coerce')\n",
    "    \n",
    "    # Drop rows with invalid dates\n",
    "    chunk = chunk.dropna(subset=['date'])\n",
    "    \n",
    "    # Convert 'text' column to string and filter out tweets with fewer than 5 words\n",
    "    chunk['text'] = chunk['text'].astype(str)\n",
    "    chunk = chunk[chunk['text'].str.split().str.len() > 4]\n",
    "    \n",
    "    # Sample 5000 tweets per day from this chunk\n",
    "    sampled_chunk = chunk.groupby(chunk['date'].dt.date).apply(\n",
    "        lambda x: x.sample(n=min(5000, len(x)), random_state=1)\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    # Append the sampled data to the main DataFrame\n",
    "    sampled_tweets = pd.concat([sampled_tweets, sampled_chunk], ignore_index=True)\n",
    "# Save the sampled data to a new CSV file\n",
    "sampled_tweets.to_csv('sampled_tweets_per_day.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ead93e7d-ce39-4576-beeb-bf2c056f3676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-05</th>\n",
       "      <td>1694</td>\n",
       "      <td>1694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-06</th>\n",
       "      <td>3273</td>\n",
       "      <td>3273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-07</th>\n",
       "      <td>3027</td>\n",
       "      <td>3027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-08</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-09</th>\n",
       "      <td>4344</td>\n",
       "      <td>4344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-16</th>\n",
       "      <td>8959</td>\n",
       "      <td>8959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-20</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-21</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01</th>\n",
       "      <td>7571</td>\n",
       "      <td>7571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  text\n",
       "date                  \n",
       "2021-02-05  1694  1694\n",
       "2021-02-06  3273  3273\n",
       "2021-02-07  3027  3027\n",
       "2021-02-08  5000  5000\n",
       "2021-02-09  4344  4344\n",
       "...          ...   ...\n",
       "2022-11-16  8959  8959\n",
       "2022-11-20  5000  5000\n",
       "2022-11-21  5000  5000\n",
       "2022-12-27   235   235\n",
       "2023-03-01  7571  7571\n",
       "\n",
       "[216 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_tweets.groupby(sampled_tweets['date'].dt.date).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4d723c5-ca06-4622-b96f-1ce84934dae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/hamid/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import pandas as pd\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4c1ee4a-bca5-4243-86c8-534dbda843dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.ads_keywords = [\"buy\", \"discount\", \"promo\", \"sale\", \"airdrop\", \"giveaway\"]\n",
    "\n",
    "    def preprocess_with_lemmatization(self, text):\n",
    "        text_list = text.split()\n",
    "        text_list = [self.lemmatizer.lemmatize(word) for word in text_list]\n",
    "        return \" \".join(text_list)\n",
    "\n",
    "    def remove_URL(self, text):\n",
    "        return re.sub(r\"(?:https?://|www\\.)\\S+\\.\\S+\", \"\", text)\n",
    "\n",
    "    def lowercase_tweet(self, text):\n",
    "        return text.lower()\n",
    "\n",
    "    def remove_punctuations(self, text):\n",
    "        exclude = set(string.punctuation)\n",
    "        for char in ['!', '?', '%', '$', '&']:\n",
    "            exclude.remove(char)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def replace_with_BTC(self, text):\n",
    "        return re.sub(r\"Bitcoin|bitcoin|btc|BitCoin\", \"BTC\", text)\n",
    "\n",
    "    def remove_user_ids(self, text):\n",
    "        return re.sub(r\"@\\w+\", \" \", text)\n",
    "\n",
    "    def remove_emojis_and_symbols(self, text):\n",
    "        # Remove emojis and other non-alphanumeric symbols\n",
    "        return re.sub(r\"[^\\w\\s.,!?%&$]\", \" \", text)\n",
    "\n",
    "    def remove_currency_numbers(self, text):\n",
    "        # Remove numbers with $ or % symbols that likely represent prices/percentages\n",
    "        text = re.sub(r\"\\$\\s*\\d+(?:\\.\\d+)?\", \" \", text)  # Remove prices like \"$123\" or \"$ 123.45\"\n",
    "        text = re.sub(r\"\\b\\d+(?:\\.\\d+)?\\s*%\", \" \", text)  # Remove percentages like \"5%\" or \"123.45 %\"\n",
    "        return text\n",
    "\n",
    "    def remove_standalone_numbers(self, text):\n",
    "        # Remove standalone numbers (e.g., 378500), but keep numbers with % or $ for potential context\n",
    "        return re.sub(r\"\\b\\d+\\b\", \" \", text)\n",
    "\n",
    "    def is_ads(self, text):\n",
    "        for ads_keyword in self.ads_keywords:\n",
    "            if ads_keyword in text:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        text = self.remove_URL(text)\n",
    "        text = self.lowercase_tweet(text)\n",
    "        text = self.remove_emojis_and_symbols(text)\n",
    "        text = self.remove_currency_numbers(text)\n",
    "        text = self.remove_standalone_numbers(text)\n",
    "        text = self.remove_punctuations(text)\n",
    "        text = self.replace_with_BTC(text)\n",
    "        text = self.remove_user_ids(text)\n",
    "        text = self.preprocess_with_lemmatization(text)\n",
    "        return text\n",
    "\n",
    "    def preprocess_tweets_df(self, tweets_df):\n",
    "        tweets_df['cleaned_text'] = tweets_df['text'].apply(self.preprocess_text)\n",
    "        tweets_df = tweets_df[~tweets_df['cleaned_text'].apply(self.is_ads)]\n",
    "        return tweets_df\n",
    "\n",
    "preprocessor = TweetPreprocessor()\n",
    "cleaned_tweets_df = preprocessor.preprocess_tweets_df(sampled_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e183d52-e5d9-4c58-a71b-e4d962b1a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets_df = cleaned_tweets_df[[\"date\", \"cleaned_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a617060a-06ef-4fcf-96c9-adb12551a17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          2021-02-05\n",
       "1          2021-02-05\n",
       "2          2021-02-05\n",
       "3          2021-02-05\n",
       "4          2021-02-05\n",
       "              ...    \n",
       "1090793    2023-03-01\n",
       "1090794    2023-03-01\n",
       "1090795    2023-03-01\n",
       "1090796    2023-03-01\n",
       "1090797    2023-03-01\n",
       "Name: date, Length: 908235, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_tweets_df.date.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d0ad625-d2b9-4d83-8245-c5599f559a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def combine_tweets(tweets_df):\n",
    "    combined_data = []\n",
    "    overlap = 20  # Number of words to overlap\n",
    "    chunk_size = 200  # Target number of words per chunk\n",
    "    \n",
    "    current_text = []\n",
    "    current_date = None\n",
    "    \n",
    "    for index, row in tweets_df.iterrows():\n",
    "        tweet_text = row['cleaned_text']\n",
    "        tweet_date = row['date'].strftime(\"%Y-%m-%d\")  # Get only the date without time\n",
    "\n",
    "        # Split tweet text into words\n",
    "        words = tweet_text.split()\n",
    "        \n",
    "        # Append words to the current chunk\n",
    "        current_text.extend(words)\n",
    "        \n",
    "        # If current_date is None, set it to the date of the first tweet in the chunk\n",
    "        if current_date is None:\n",
    "            current_date = tweet_date\n",
    "\n",
    "        # Process the current chunk if it reaches the chunk size\n",
    "        while len(current_text) >= chunk_size:\n",
    "            # Create a chunk of the first 200 words\n",
    "            chunk = \" \".join(current_text[:chunk_size])\n",
    "            \n",
    "            # Append the chunk with its date to the combined data\n",
    "            combined_data.append({\"date\": current_date, \"text\": chunk})\n",
    "            \n",
    "            # Remove the first 180 words, leaving a 20-word overlap for the next chunk\n",
    "            current_text = current_text[chunk_size - overlap:]\n",
    "            \n",
    "            # Reset the date for the next chunk to the last tweet's date in the current chunk\n",
    "            current_date = tweet_date\n",
    "\n",
    "    # Handle any remaining words in the last chunk if it's not empty\n",
    "    if current_text:\n",
    "        combined_data.append({\"date\": current_date, \"text\": \" \".join(current_text)})\n",
    "\n",
    "    # Create a new DataFrame with the combined data\n",
    "    combined_tweets_df = pd.DataFrame(combined_data)\n",
    "    return combined_tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3b596629-67b8-41ba-a360-a988b58971fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tweets_df = combine_tweets(cleaned_tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f24a7895-358a-4730-89f8-a0785c3ffd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'out BTC BTC cryptocurrency price update in $eur hour $BTC $eth $xrp this year we are introducing workshop at bitblockboom guy swann will host making sense of lightning another in last minute $knc is still looking good BTC BTC dogecointothemoon kleverio kucoincom check this out! $klv is a great project $klv already tradable at world s no cryptocurrency mirBTC mcnicollme yeah right? now a day any conversation that mention BTC immediately catch me BTC BTC price update in $usd hour $BTC $eth $xrp crypto trading? BTC binance BTC crypto BTC will be inevitable for every country BTC cryptocurrency market crypto BTC cryptocurrency blockchain BTC ethereum forex real research app instant payment live withdraw payment proof watch till the end my answer to is learning blockchain technology good for the future? future blockchain the first digital cryptocurrency you can mine on your phone! pi make crypto mining easy and free! watch the vi $omg usd $BTC BTC BTC altcoins crypto michaelsaylor hour availability degree of service and safe for your wealth and there are only million of BTC BTC privacy findora v BTC &amp ethereum all input &amp output of transaction in BTC are visible on chain a today in BTC'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_tweets_df.text.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "449581ea-c6e4-41b2-9ee9-9d2506ea19b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tweets_df.to_csv(\"../raw/combined_2021_to_2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9238b24b-767d-4b78-9d71-0a35443bd4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tweets_df = pd.read_csv(\"../raw/combined_2021_to_2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46a7110b-5cc9-44e2-b912-69c307996384",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_votes = pd.read_csv(\"../raw/majority_prediction_of_2021_2023.csv\", names=[\"id\", \"prediction\"], usecols=[\"prediction\"], skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca68f543-9d39-4ce5-99cb-21c3719398ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df = pd.concat([combined_tweets_df, majority_votes], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc2cdc40-1e5b-42a1-b918-bf2a91df0af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df = predicted_df[[\"date\", \"text\", \"prediction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "986de71c-9cb5-464d-b2d3-590b8d3714ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10590/2423539163.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  predicted_df.date = pd.to_datetime(predicted_df.date)\n"
     ]
    }
   ],
   "source": [
    "predicted_df.date = pd.to_datetime(predicted_df.date)\n",
    "predicted_df.set_index(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47008884-47c3-4e52-a929-5963ead8c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "address = \"../raw/optimized_labeled.csv\"\n",
    "# Loading the price data\n",
    "columns = [\"timestamp\", \"close\", \"open\", \"high\", \"low\", \"volume\", \"label\", \"volatility\", \"window_start\", \"upper_barrier\", \"lower_barrier\"]\n",
    "labeled_df = pandas_data_loader(address, columns, partial(to_index, \"timestamp\"), partial(index_to_datetime, unit=None))\n",
    "labeled_df.rename(inplace=True ,columns={\"label\": \"previous_label\"})\n",
    "labeled_df = labeled_df.sort_index()\n",
    "labeled_df.rename(columns={'label': 'previous_label'}, inplace=True)\n",
    "# Shift the labels such that for each day, the label is set to the next day's label\n",
    "labeled_df[\"next_day_label\"] = labeled_df.previous_label.shift(-1)\n",
    "labeled_df[\"next_day_window_start\"] = labeled_df.window_start.shift(-1)\n",
    "labeled_df.loc[labeled_df.iloc[0].name, 'next_day_window_start'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c375ccd3-9417-440d-84af-8b6ce0a7a678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "next_day_label\n",
       "2.0    43221\n",
       "0.0    38992\n",
       "1.0    28342\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = predicted_df.merge(\n",
    "    labeled_df[[\"next_day_label\", 'next_day_window_start', 'previous_label']], left_index=True, right_index=True, how=\"left\"\n",
    ")\n",
    "merged_df.dropna(inplace=True)\n",
    "merged_df.next_day_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ffa3b526-3a96-4696-9a94-6f56019b8480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prediction</th>\n",
       "      <th>next_day_label</th>\n",
       "      <th>next_day_window_start</th>\n",
       "      <th>previous_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-05</th>\n",
       "      <td>in case you want to seel your BTC please dm as...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05</th>\n",
       "      <td>free coin value BTC like cryptocurrency news B...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05</th>\n",
       "      <td>to BTC news roundup for feb by market daily cr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05</th>\n",
       "      <td>late i m going to wait until it hit i ve got v...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05</th>\n",
       "      <td>believe you show me a hedge fund that doesn t ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01</th>\n",
       "      <td>use the moneyprinter to paper over reality BTC...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01</th>\n",
       "      <td>cryptonews investing eth BTCnews BTC wa tradin...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01</th>\n",
       "      <td>nftart metaverse larvaapes opensea megapunks l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01</th>\n",
       "      <td>bnx are you looking for a way to recover your ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01</th>\n",
       "      <td>BTCs together! get an exciting experience on i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110555 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text  prediction  \\\n",
       "date                                                                        \n",
       "2021-02-05  in case you want to seel your BTC please dm as...           1   \n",
       "2021-02-05  free coin value BTC like cryptocurrency news B...           1   \n",
       "2021-02-05  to BTC news roundup for feb by market daily cr...           1   \n",
       "2021-02-05  late i m going to wait until it hit i ve got v...           0   \n",
       "2021-02-05  believe you show me a hedge fund that doesn t ...           1   \n",
       "...                                                       ...         ...   \n",
       "2023-03-01  use the moneyprinter to paper over reality BTC...           0   \n",
       "2023-03-01  cryptonews investing eth BTCnews BTC wa tradin...           2   \n",
       "2023-03-01  nftart metaverse larvaapes opensea megapunks l...           1   \n",
       "2023-03-01  bnx are you looking for a way to recover your ...           0   \n",
       "2023-03-01  BTCs together! get an exciting experience on i...           1   \n",
       "\n",
       "            next_day_label next_day_window_start  previous_label  \n",
       "date                                                              \n",
       "2021-02-05             1.0                 False               1  \n",
       "2021-02-05             1.0                 False               1  \n",
       "2021-02-05             1.0                 False               1  \n",
       "2021-02-05             1.0                 False               1  \n",
       "2021-02-05             1.0                 False               1  \n",
       "...                    ...                   ...             ...  \n",
       "2023-03-01             0.0                 False               0  \n",
       "2023-03-01             0.0                 False               0  \n",
       "2023-03-01             0.0                 False               0  \n",
       "2023-03-01             0.0                 False               0  \n",
       "2023-03-01             0.0                 False               0  \n",
       "\n",
       "[110555 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e424034-f705-4e4a-ac44-d4841d39fdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.33551625887567277}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics_classification(merged_df.previous_label, merged_df.prediction, [], metrics_to_return=[\"accuracy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
